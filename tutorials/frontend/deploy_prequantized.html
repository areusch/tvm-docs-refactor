





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy a Framework-prequantized Model with TVM &mdash; tvm 0.8.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.8.dev0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html#first-steps-with-tvm">First Steps with TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">Dive Into</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../import_models/index.html">Import Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../describe_models/index.html">Describe Models to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optimize/index.html">Optimize Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../microtvm/index.html">microTVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">Developer How-To Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
</ul>
<p class="caption"><span class="caption-text">Design Documents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/links.html">Links to Other API References</a></li>
</ul>
<p class="caption"><span class="caption-text">MISC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
      <li>Deploy a Framework-prequantized Model with TVM</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/frontend/deploy_prequantized.rst.txt" rel="nofollow"> <img src="../../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-frontend-deploy-prequantized-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="deploy-a-framework-prequantized-model-with-tvm">
<span id="sphx-glr-tutorials-frontend-deploy-prequantized-py"></span><h1>Deploy a Framework-prequantized Model with TVM<a class="headerlink" href="#deploy-a-framework-prequantized-model-with-tvm" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/masahi">Masahiro Masuda</a></p>
<p>This is a tutorial on loading models quantized by deep learning frameworks into TVM.
Pre-quantized model import is one of the quantization support we have in TVM. More details on
the quantization story in TVM can be found
<a class="reference external" href="https://discuss.tvm.apache.org/t/quantization-story/3920">here</a>.</p>
<p>Here, we demonstrate how to load and run models quantized by PyTorch, MXNet, and TFLite.
Once loaded, we can run compiled, quantized models on any hardware TVM supports.</p>
<p>First, necessary imports</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision.models.quantization</span> <span class="kn">import</span> <span class="n">mobilenet</span> <span class="k">as</span> <span class="n">qmobilenet</span>

<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="kn">import</span> <span class="n">download_testdata</span>
</pre></div>
</div>
<p>Helper functions to run the demo</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_transform</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>

    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
            <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
            <span class="n">normalize</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">get_real_image</span><span class="p">(</span><span class="n">im_height</span><span class="p">,</span> <span class="n">im_width</span><span class="p">):</span>
    <span class="n">img_url</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true&quot;</span>
    <span class="n">img_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">img_url</span><span class="p">,</span> <span class="s2">&quot;cat.png&quot;</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">im_height</span><span class="p">,</span> <span class="n">im_width</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_imagenet_input</span><span class="p">():</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">get_real_image</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span>
    <span class="n">preprocess</span> <span class="o">=</span> <span class="n">get_transform</span><span class="p">()</span>
    <span class="n">pt_tensor</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">pt_tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_synset</span><span class="p">():</span>
    <span class="n">synset_url</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="s2">&quot;https://gist.githubusercontent.com/zhreshold/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;4d0b62f3d01426887599d4f7ede23ee5/raw/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;596b27d23537e5a1b5751d2b0481ef172f58b539/&quot;</span><span class="p">,</span>
            <span class="s2">&quot;imagenet1000_clsid_to_human.txt&quot;</span><span class="p">,</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="n">synset_name</span> <span class="o">=</span> <span class="s2">&quot;imagenet1000_clsid_to_human.txt&quot;</span>
    <span class="n">synset_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">synset_url</span><span class="p">,</span> <span class="n">synset_name</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">synset_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">eval</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>


<span class="k">def</span> <span class="nf">run_tvm_model</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;llvm&quot;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tvm</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">PassContext</span><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">lib</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

    <span class="n">runtime</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">graph_runtime</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">lib</span><span class="p">[</span><span class="s2">&quot;default&quot;</span><span class="p">](</span><span class="n">tvm</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>

    <span class="n">runtime</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="n">input_name</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="n">runtime</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">runtime</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">runtime</span>
</pre></div>
</div>
<p>A mapping from label to class name, to verify that the outputs from models below
are reasonable</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">synset</span> <span class="o">=</span> <span class="n">get_synset</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>File /Users/andrew/.tvm_test_data/data/imagenet1000_clsid_to_human.txt exists, skip.
</pre></div>
</div>
<p>Everyone’s favorite cat image for demonstration</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">inp</span> <span class="o">=</span> <span class="n">get_imagenet_input</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>File /Users/andrew/.tvm_test_data/data/cat.png exists, skip.
</pre></div>
</div>
<div class="section" id="deploy-a-quantized-pytorch-model">
<h2>Deploy a quantized PyTorch Model<a class="headerlink" href="#deploy-a-quantized-pytorch-model" title="Permalink to this headline">¶</a></h2>
<p>First, we demonstrate how to load deep learning models quantized by PyTorch,
using our PyTorch frontend.</p>
<p>Please refer to the PyTorch static quantization tutorial below to learn about
their quantization workflow.
<a class="reference external" href="https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html">https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html</a></p>
<p>We use this function to quantize PyTorch models.
In short, this function takes a floating point model and converts it to uint8.
The model is per-channel quantized.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">quantize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fuse_model</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="n">qconfig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">get_default_qconfig</span><span class="p">(</span><span class="s2">&quot;fbgemm&quot;</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Dummy calibration</span>
    <span class="n">model</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="load-quantization-ready-pretrained-mobilenet-v2-model-from-torchvision">
<h2>Load quantization-ready, pretrained Mobilenet v2 model from torchvision<a class="headerlink" href="#load-quantization-ready-pretrained-mobilenet-v2-model-from-torchvision" title="Permalink to this headline">¶</a></h2>
<p>We choose mobilenet v2 because this model was trained with quantization aware
training. Other models require a full post training calibration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qmodel</span> <span class="o">=</span> <span class="n">qmobilenet</span><span class="o">.</span><span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading: &quot;https://download.pytorch.org/models/mobilenet_v2-b0353104.pth&quot; to /Users/andrew/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth

0.1%
0.1%
0.2%
0.2%
0.3%
0.3%
0.4%
0.5%
0.5%
0.6%
0.6%
0.7%
0.7%
0.8%
0.9%
0.9%
1.0%
1.0%
1.1%
1.2%
1.2%
1.3%
1.3%
1.4%
1.4%
1.5%
1.6%
1.6%
1.7%
1.7%
1.8%
1.8%
1.9%
2.0%
2.0%
2.1%
2.1%
2.2%
2.2%
2.3%
2.4%
2.4%
2.5%
2.5%
2.6%
2.7%
2.7%
2.8%
2.8%
2.9%
2.9%
3.0%
3.1%
3.1%
3.2%
3.2%
3.3%
3.3%
3.4%
3.5%
3.5%
3.6%
3.6%
3.7%
3.7%
3.8%
3.9%
3.9%
4.0%
4.0%
4.1%
4.1%
4.2%
4.3%
4.3%
4.4%
4.4%
4.5%
4.6%
4.6%
4.7%
4.7%
4.8%
4.8%
4.9%
5.0%
5.0%
5.1%
5.1%
5.2%
5.2%
5.3%
5.4%
5.4%
5.5%
5.5%
5.6%
5.6%
5.7%
5.8%
5.8%
5.9%
5.9%
6.0%
6.1%
6.1%
6.2%
6.2%
6.3%
6.3%
6.4%
6.5%
6.5%
6.6%
6.6%
6.7%
6.7%
6.8%
6.9%
6.9%
7.0%
7.0%
7.1%
7.1%
7.2%
7.3%
7.3%
7.4%
7.4%
7.5%
7.6%
7.6%
7.7%
7.7%
7.8%
7.8%
7.9%
8.0%
8.0%
8.1%
8.1%
8.2%
8.2%
8.3%
8.4%
8.4%
8.5%
8.5%
8.6%
8.6%
8.7%
8.8%
8.8%
8.9%
8.9%
9.0%
9.0%
9.1%
9.2%
9.2%
9.3%
9.3%
9.4%
9.5%
9.5%
9.6%
9.6%
9.7%
9.7%
9.8%
9.9%
9.9%
10.0%
10.0%
10.1%
10.1%
10.2%
10.3%
10.3%
10.4%
10.4%
10.5%
10.5%
10.6%
10.7%
10.7%
10.8%
10.8%
10.9%
11.0%
11.0%
11.1%
11.1%
11.2%
11.2%
11.3%
11.4%
11.4%
11.5%
11.5%
11.6%
11.6%
11.7%
11.8%
11.8%
11.9%
11.9%
12.0%
12.0%
12.1%
12.2%
12.2%
12.3%
12.3%
12.4%
12.4%
12.5%
12.6%
12.6%
12.7%
12.7%
12.8%
12.9%
12.9%
13.0%
13.0%
13.1%
13.1%
13.2%
13.3%
13.3%
13.4%
13.4%
13.5%
13.5%
13.6%
13.7%
13.7%
13.8%
13.8%
13.9%
13.9%
14.0%
14.1%
14.1%
14.2%
14.2%
14.3%
14.4%
14.4%
14.5%
14.5%
14.6%
14.6%
14.7%
14.8%
14.8%
14.9%
14.9%
15.0%
15.0%
15.1%
15.2%
15.2%
15.3%
15.3%
15.4%
15.4%
15.5%
15.6%
15.6%
15.7%
15.7%
15.8%
15.9%
15.9%
16.0%
16.0%
16.1%
16.1%
16.2%
16.3%
16.3%
16.4%
16.4%
16.5%
16.5%
16.6%
16.7%
16.7%
16.8%
16.8%
16.9%
16.9%
17.0%
17.1%
17.1%
17.2%
17.2%
17.3%
17.3%
17.4%
17.5%
17.5%
17.6%
17.6%
17.7%
17.8%
17.8%
17.9%
17.9%
18.0%
18.0%
18.1%
18.2%
18.2%
18.3%
18.3%
18.4%
18.4%
18.5%
18.6%
18.6%
18.7%
18.7%
18.8%
18.8%
18.9%
19.0%
19.0%
19.1%
19.1%
19.2%
19.3%
19.3%
19.4%
19.4%
19.5%
19.5%
19.6%
19.7%
19.7%
19.8%
19.8%
19.9%
19.9%
20.0%
20.1%
20.1%
20.2%
20.2%
20.3%
20.3%
20.4%
20.5%
20.5%
20.6%
20.6%
20.7%
20.7%
20.8%
20.9%
20.9%
21.0%
21.0%
21.1%
21.2%
21.2%
21.3%
21.3%
21.4%
21.4%
21.5%
21.6%
21.6%
21.7%
21.7%
21.8%
21.8%
21.9%
22.0%
22.0%
22.1%
22.1%
22.2%
22.2%
22.3%
22.4%
22.4%
22.5%
22.5%
22.6%
22.7%
22.7%
22.8%
22.8%
22.9%
22.9%
23.0%
23.1%
23.1%
23.2%
23.2%
23.3%
23.3%
23.4%
23.5%
23.5%
23.6%
23.6%
23.7%
23.7%
23.8%
23.9%
23.9%
24.0%
24.0%
24.1%
24.2%
24.2%
24.3%
24.3%
24.4%
24.4%
24.5%
24.6%
24.6%
24.7%
24.7%
24.8%
24.8%
24.9%
25.0%
25.0%
25.1%
25.1%
25.2%
25.2%
25.3%
25.4%
25.4%
25.5%
25.5%
25.6%
25.6%
25.7%
25.8%
25.8%
25.9%
25.9%
26.0%
26.1%
26.1%
26.2%
26.2%
26.3%
26.3%
26.4%
26.5%
26.5%
26.6%
26.6%
26.7%
26.7%
26.8%
26.9%
26.9%
27.0%
27.0%
27.1%
27.1%
27.2%
27.3%
27.3%
27.4%
27.4%
27.5%
27.6%
27.6%
27.7%
27.7%
27.8%
27.8%
27.9%
28.0%
28.0%
28.1%
28.1%
28.2%
28.2%
28.3%
28.4%
28.4%
28.5%
28.5%
28.6%
28.6%
28.7%
28.8%
28.8%
28.9%
28.9%
29.0%
29.0%
29.1%
29.2%
29.2%
29.3%
29.3%
29.4%
29.5%
29.5%
29.6%
29.6%
29.7%
29.7%
29.8%
29.9%
29.9%
30.0%
30.0%
30.1%
30.1%
30.2%
30.3%
30.3%
30.4%
30.4%
30.5%
30.5%
30.6%
30.7%
30.7%
30.8%
30.8%
30.9%
31.0%
31.0%
31.1%
31.1%
31.2%
31.2%
31.3%
31.4%
31.4%
31.5%
31.5%
31.6%
31.6%
31.7%
31.8%
31.8%
31.9%
31.9%
32.0%
32.0%
32.1%
32.2%
32.2%
32.3%
32.3%
32.4%
32.4%
32.5%
32.6%
32.6%
32.7%
32.7%
32.8%
32.9%
32.9%
33.0%
33.0%
33.1%
33.1%
33.2%
33.3%
33.3%
33.4%
33.4%
33.5%
33.5%
33.6%
33.7%
33.7%
33.8%
33.8%
33.9%
33.9%
34.0%
34.1%
34.1%
34.2%
34.2%
34.3%
34.4%
34.4%
34.5%
34.5%
34.6%
34.6%
34.7%
34.8%
34.8%
34.9%
34.9%
35.0%
35.0%
35.1%
35.2%
35.2%
35.3%
35.3%
35.4%
35.4%
35.5%
35.6%
35.6%
35.7%
35.7%
35.8%
35.9%
35.9%
36.0%
36.0%
36.1%
36.1%
36.2%
36.3%
36.3%
36.4%
36.4%
36.5%
36.5%
36.6%
36.7%
36.7%
36.8%
36.8%
36.9%
36.9%
37.0%
37.1%
37.1%
37.2%
37.2%
37.3%
37.3%
37.4%
37.5%
37.5%
37.6%
37.6%
37.7%
37.8%
37.8%
37.9%
37.9%
38.0%
38.0%
38.1%
38.2%
38.2%
38.3%
38.3%
38.4%
38.4%
38.5%
38.6%
38.6%
38.7%
38.7%
38.8%
38.8%
38.9%
39.0%
39.0%
39.1%
39.1%
39.2%
39.3%
39.3%
39.4%
39.4%
39.5%
39.5%
39.6%
39.7%
39.7%
39.8%
39.8%
39.9%
39.9%
40.0%
40.1%
40.1%
40.2%
40.2%
40.3%
40.3%
40.4%
40.5%
40.5%
40.6%
40.6%
40.7%
40.7%
40.8%
40.9%
40.9%
41.0%
41.0%
41.1%
41.2%
41.2%
41.3%
41.3%
41.4%
41.4%
41.5%
41.6%
41.6%
41.7%
41.7%
41.8%
41.8%
41.9%
42.0%
42.0%
42.1%
42.1%
42.2%
42.2%
42.3%
42.4%
42.4%
42.5%
42.5%
42.6%
42.7%
42.7%
42.8%
42.8%
42.9%
42.9%
43.0%
43.1%
43.1%
43.2%
43.2%
43.3%
43.3%
43.4%
43.5%
43.5%
43.6%
43.6%
43.7%
43.7%
43.8%
43.9%
43.9%
44.0%
44.0%
44.1%
44.2%
44.2%
44.3%
44.3%
44.4%
44.4%
44.5%
44.6%
44.6%
44.7%
44.7%
44.8%
44.8%
44.9%
45.0%
45.0%
45.1%
45.1%
45.2%
45.2%
45.3%
45.4%
45.4%
45.5%
45.5%
45.6%
45.6%
45.7%
45.8%
45.8%
45.9%
45.9%
46.0%
46.1%
46.1%
46.2%
46.2%
46.3%
46.3%
46.4%
46.5%
46.5%
46.6%
46.6%
46.7%
46.7%
46.8%
46.9%
46.9%
47.0%
47.0%
47.1%
47.1%
47.2%
47.3%
47.3%
47.4%
47.4%
47.5%
47.6%
47.6%
47.7%
47.7%
47.8%
47.8%
47.9%
48.0%
48.0%
48.1%
48.1%
48.2%
48.2%
48.3%
48.4%
48.4%
48.5%
48.5%
48.6%
48.6%
48.7%
48.8%
48.8%
48.9%
48.9%
49.0%
49.0%
49.1%
49.2%
49.2%
49.3%
49.3%
49.4%
49.5%
49.5%
49.6%
49.6%
49.7%
49.7%
49.8%
49.9%
49.9%
50.0%
50.0%
50.1%
50.1%
50.2%
50.3%
50.3%
50.4%
50.4%
50.5%
50.5%
50.6%
50.7%
50.7%
50.8%
50.8%
50.9%
51.0%
51.0%
51.1%
51.1%
51.2%
51.2%
51.3%
51.4%
51.4%
51.5%
51.5%
51.6%
51.6%
51.7%
51.8%
51.8%
51.9%
51.9%
52.0%
52.0%
52.1%
52.2%
52.2%
52.3%
52.3%
52.4%
52.5%
52.5%
52.6%
52.6%
52.7%
52.7%
52.8%
52.9%
52.9%
53.0%
53.0%
53.1%
53.1%
53.2%
53.3%
53.3%
53.4%
53.4%
53.5%
53.5%
53.6%
53.7%
53.7%
53.8%
53.8%
53.9%
53.9%
54.0%
54.1%
54.1%
54.2%
54.2%
54.3%
54.4%
54.4%
54.5%
54.5%
54.6%
54.6%
54.7%
54.8%
54.8%
54.9%
54.9%
55.0%
55.0%
55.1%
55.2%
55.2%
55.3%
55.3%
55.4%
55.4%
55.5%
55.6%
55.6%
55.7%
55.7%
55.8%
55.9%
55.9%
56.0%
56.0%
56.1%
56.1%
56.2%
56.3%
56.3%
56.4%
56.4%
56.5%
56.5%
56.6%
56.7%
56.7%
56.8%
56.8%
56.9%
56.9%
57.0%
57.1%
57.1%
57.2%
57.2%
57.3%
57.3%
57.4%
57.5%
57.5%
57.6%
57.6%
57.7%
57.8%
57.8%
57.9%
57.9%
58.0%
58.0%
58.1%
58.2%
58.2%
58.3%
58.3%
58.4%
58.4%
58.5%
58.6%
58.6%
58.7%
58.7%
58.8%
58.8%
58.9%
59.0%
59.0%
59.1%
59.1%
59.2%
59.3%
59.3%
59.4%
59.4%
59.5%
59.5%
59.6%
59.7%
59.7%
59.8%
59.8%
59.9%
59.9%
60.0%
60.1%
60.1%
60.2%
60.2%
60.3%
60.3%
60.4%
60.5%
60.5%
60.6%
60.6%
60.7%
60.7%
60.8%
60.9%
60.9%
61.0%
61.0%
61.1%
61.2%
61.2%
61.3%
61.3%
61.4%
61.4%
61.5%
61.6%
61.6%
61.7%
61.7%
61.8%
61.8%
61.9%
62.0%
62.0%
62.1%
62.1%
62.2%
62.2%
62.3%
62.4%
62.4%
62.5%
62.5%
62.6%
62.7%
62.7%
62.8%
62.8%
62.9%
62.9%
63.0%
63.1%
63.1%
63.2%
63.2%
63.3%
63.3%
63.4%
63.5%
63.5%
63.6%
63.6%
63.7%
63.7%
63.8%
63.9%
63.9%
64.0%
64.0%
64.1%
64.2%
64.2%
64.3%
64.3%
64.4%
64.4%
64.5%
64.6%
64.6%
64.7%
64.7%
64.8%
64.8%
64.9%
65.0%
65.0%
65.1%
65.1%
65.2%
65.2%
65.3%
65.4%
65.4%
65.5%
65.5%
65.6%
65.6%
65.7%
65.8%
65.8%
65.9%
65.9%
66.0%
66.1%
66.1%
66.2%
66.2%
66.3%
66.3%
66.4%
66.5%
66.5%
66.6%
66.6%
66.7%
66.7%
66.8%
66.9%
66.9%
67.0%
67.0%
67.1%
67.1%
67.2%
67.3%
67.3%
67.4%
67.4%
67.5%
67.6%
67.6%
67.7%
67.7%
67.8%
67.8%
67.9%
68.0%
68.0%
68.1%
68.1%
68.2%
68.2%
68.3%
68.4%
68.4%
68.5%
68.5%
68.6%
68.6%
68.7%
68.8%
68.8%
68.9%
68.9%
69.0%
69.0%
69.1%
69.2%
69.2%
69.3%
69.3%
69.4%
69.5%
69.5%
69.6%
69.6%
69.7%
69.7%
69.8%
69.9%
69.9%
70.0%
70.0%
70.1%
70.1%
70.2%
70.3%
70.3%
70.4%
70.4%
70.5%
70.5%
70.6%
70.7%
70.7%
70.8%
70.8%
70.9%
71.0%
71.0%
71.1%
71.1%
71.2%
71.2%
71.3%
71.4%
71.4%
71.5%
71.5%
71.6%
71.6%
71.7%
71.8%
71.8%
71.9%
71.9%
72.0%
72.0%
72.1%
72.2%
72.2%
72.3%
72.3%
72.4%
72.5%
72.5%
72.6%
72.6%
72.7%
72.7%
72.8%
72.9%
72.9%
73.0%
73.0%
73.1%
73.1%
73.2%
73.3%
73.3%
73.4%
73.4%
73.5%
73.5%
73.6%
73.7%
73.7%
73.8%
73.8%
73.9%
73.9%
74.0%
74.1%
74.1%
74.2%
74.2%
74.3%
74.4%
74.4%
74.5%
74.5%
74.6%
74.6%
74.7%
74.8%
74.8%
74.9%
74.9%
75.0%
75.0%
75.1%
75.2%
75.2%
75.3%
75.3%
75.4%
75.4%
75.5%
75.6%
75.6%
75.7%
75.7%
75.8%
75.9%
75.9%
76.0%
76.0%
76.1%
76.1%
76.2%
76.3%
76.3%
76.4%
76.4%
76.5%
76.5%
76.6%
76.7%
76.7%
76.8%
76.8%
76.9%
76.9%
77.0%
77.1%
77.1%
77.2%
77.2%
77.3%
77.3%
77.4%
77.5%
77.5%
77.6%
77.6%
77.7%
77.8%
77.8%
77.9%
77.9%
78.0%
78.0%
78.1%
78.2%
78.2%
78.3%
78.3%
78.4%
78.4%
78.5%
78.6%
78.6%
78.7%
78.7%
78.8%
78.8%
78.9%
79.0%
79.0%
79.1%
79.1%
79.2%
79.3%
79.3%
79.4%
79.4%
79.5%
79.5%
79.6%
79.7%
79.7%
79.8%
79.8%
79.9%
79.9%
80.0%
80.1%
80.1%
80.2%
80.2%
80.3%
80.3%
80.4%
80.5%
80.5%
80.6%
80.6%
80.7%
80.8%
80.8%
80.9%
80.9%
81.0%
81.0%
81.1%
81.2%
81.2%
81.3%
81.3%
81.4%
81.4%
81.5%
81.6%
81.6%
81.7%
81.7%
81.8%
81.8%
81.9%
82.0%
82.0%
82.1%
82.1%
82.2%
82.2%
82.3%
82.4%
82.4%
82.5%
82.5%
82.6%
82.7%
82.7%
82.8%
82.8%
82.9%
82.9%
83.0%
83.1%
83.1%
83.2%
83.2%
83.3%
83.3%
83.4%
83.5%
83.5%
83.6%
83.6%
83.7%
83.7%
83.8%
83.9%
83.9%
84.0%
84.0%
84.1%
84.2%
84.2%
84.3%
84.3%
84.4%
84.4%
84.5%
84.6%
84.6%
84.7%
84.7%
84.8%
84.8%
84.9%
85.0%
85.0%
85.1%
85.1%
85.2%
85.2%
85.3%
85.4%
85.4%
85.5%
85.5%
85.6%
85.6%
85.7%
85.8%
85.8%
85.9%
85.9%
86.0%
86.1%
86.1%
86.2%
86.2%
86.3%
86.3%
86.4%
86.5%
86.5%
86.6%
86.6%
86.7%
86.7%
86.8%
86.9%
86.9%
87.0%
87.0%
87.1%
87.1%
87.2%
87.3%
87.3%
87.4%
87.4%
87.5%
87.6%
87.6%
87.7%
87.7%
87.8%
87.8%
87.9%
88.0%
88.0%
88.1%
88.1%
88.2%
88.2%
88.3%
88.4%
88.4%
88.5%
88.5%
88.6%
88.6%
88.7%
88.8%
88.8%
88.9%
88.9%
89.0%
89.0%
89.1%
89.2%
89.2%
89.3%
89.3%
89.4%
89.5%
89.5%
89.6%
89.6%
89.7%
89.7%
89.8%
89.9%
89.9%
90.0%
90.0%
90.1%
90.1%
90.2%
90.3%
90.3%
90.4%
90.4%
90.5%
90.5%
90.6%
90.7%
90.7%
90.8%
90.8%
90.9%
91.0%
91.0%
91.1%
91.1%
91.2%
91.2%
91.3%
91.4%
91.4%
91.5%
91.5%
91.6%
91.6%
91.7%
91.8%
91.8%
91.9%
91.9%
92.0%
92.0%
92.1%
92.2%
92.2%
92.3%
92.3%
92.4%
92.5%
92.5%
92.6%
92.6%
92.7%
92.7%
92.8%
92.9%
92.9%
93.0%
93.0%
93.1%
93.1%
93.2%
93.3%
93.3%
93.4%
93.4%
93.5%
93.5%
93.6%
93.7%
93.7%
93.8%
93.8%
93.9%
93.9%
94.0%
94.1%
94.1%
94.2%
94.2%
94.3%
94.4%
94.4%
94.5%
94.5%
94.6%
94.6%
94.7%
94.8%
94.8%
94.9%
94.9%
95.0%
95.0%
95.1%
95.2%
95.2%
95.3%
95.3%
95.4%
95.4%
95.5%
95.6%
95.6%
95.7%
95.7%
95.8%
95.9%
95.9%
96.0%
96.0%
96.1%
96.1%
96.2%
96.3%
96.3%
96.4%
96.4%
96.5%
96.5%
96.6%
96.7%
96.7%
96.8%
96.8%
96.9%
96.9%
97.0%
97.1%
97.1%
97.2%
97.2%
97.3%
97.3%
97.4%
97.5%
97.5%
97.6%
97.6%
97.7%
97.8%
97.8%
97.9%
97.9%
98.0%
98.0%
98.1%
98.2%
98.2%
98.3%
98.3%
98.4%
98.4%
98.5%
98.6%
98.6%
98.7%
98.7%
98.8%
98.8%
98.9%
99.0%
99.0%
99.1%
99.1%
99.2%
99.3%
99.3%
99.4%
99.4%
99.5%
99.5%
99.6%
99.7%
99.7%
99.8%
99.8%
99.9%
99.9%
100.0%
</pre></div>
</div>
</div>
<div class="section" id="quantize-trace-and-run-the-pytorch-mobilenet-v2-model">
<h2>Quantize, trace and run the PyTorch Mobilenet v2 model<a class="headerlink" href="#quantize-trace-and-run-the-pytorch-mobilenet-v2-model" title="Permalink to this headline">¶</a></h2>
<p>The details are out of scope for this tutorial. Please refer to the tutorials
on the PyTorch website to learn about quantization and jit.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pt_inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
<span class="n">quantize_model</span><span class="p">(</span><span class="n">qmodel</span><span class="p">,</span> <span class="n">pt_inp</span><span class="p">)</span>
<span class="n">script_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">qmodel</span><span class="p">,</span> <span class="n">pt_inp</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">pt_result</span> <span class="o">=</span> <span class="n">script_module</span><span class="p">(</span><span class="n">pt_inp</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/Users/andrew/Library/Caches/pypoetry/virtualenvs/incubator-tvm-Rgz5PqZI-py3.7/lib/python3.7/site-packages/torch/quantization/observer.py:803: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point
  Returning default scale and zero point &quot;
</pre></div>
</div>
</div>
<div class="section" id="convert-quantized-mobilenet-v2-to-relay-qnn-using-the-pytorch-frontend">
<h2>Convert quantized Mobilenet v2 to Relay-QNN using the PyTorch frontend<a class="headerlink" href="#convert-quantized-mobilenet-v2-to-relay-qnn-using-the-pytorch-frontend" title="Permalink to this headline">¶</a></h2>
<p>The PyTorch frontend has support for converting a quantized PyTorch model to
an equivalent Relay module enriched with quantization-aware operators.
We call this representation Relay QNN dialect.</p>
<p>You can print the output from the frontend to see how quantized models are
represented.</p>
<p>You would see operators specific to quantization such as
qnn.quantize, qnn.dequantize, qnn.requantize, and qnn.conv2d etc.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">input_name</span> <span class="o">=</span> <span class="s2">&quot;input&quot;</span>  <span class="c1"># the input name can be be arbitrary for PyTorch frontend.</span>
<span class="n">input_shapes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">input_name</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))]</span>
<span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_pytorch</span><span class="p">(</span><span class="n">script_module</span><span class="p">,</span> <span class="n">input_shapes</span><span class="p">)</span>
<span class="c1"># print(mod) # comment in to see the QNN IR dump</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-and-run-the-relay-module">
<h2>Compile and run the Relay module<a class="headerlink" href="#compile-and-run-the-relay-module" title="Permalink to this headline">¶</a></h2>
<p>Once we obtained the quantized Relay module, the rest of the workflow
is the same as running floating point models. Please refer to other
tutorials for more details.</p>
<p>Under the hood, quantization specific operators are lowered to a sequence of
standard Relay operators before compilation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tvm_result</span><span class="p">,</span> <span class="n">rt_mod</span> <span class="o">=</span> <span class="n">run_tvm_model</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">input_name</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s2">&quot;llvm&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="compare-the-output-labels">
<h2>Compare the output labels<a class="headerlink" href="#compare-the-output-labels" title="Permalink to this headline">¶</a></h2>
<p>We should see identical labels printed.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pt_top3_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">pt_result</span><span class="p">[</span><span class="mi">0</span><span class="p">])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span>
<span class="n">tvm_top3_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">tvm_result</span><span class="p">[</span><span class="mi">0</span><span class="p">])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="mi">3</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PyTorch top3 labels:&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">synset</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">pt_top3_labels</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TVM top3 labels:&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">synset</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">tvm_top3_labels</span><span class="p">])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>PyTorch top3 labels: [&#39;tiger cat&#39;, &#39;Egyptian cat&#39;, &#39;weasel&#39;]
TVM top3 labels: [&#39;tiger cat&#39;, &#39;weasel&#39;, &#39;Egyptian cat&#39;]
</pre></div>
</div>
<p>However, due to the difference in numerics, in general the raw floating point
outputs are not expected to be identical. Here, we print how many floating point
output values are identical out of 1000 outputs from mobilenet v2.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%d</span><span class="s2"> in 1000 raw floating outputs identical.&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tvm_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">pt_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>159 in 1000 raw floating outputs identical.
</pre></div>
</div>
</div>
<div class="section" id="measure-performance">
<h2>Measure performance<a class="headerlink" href="#measure-performance" title="Permalink to this headline">¶</a></h2>
<p>Here we give an example of how to measure performance of TVM compiled models.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_repeat</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># should be bigger to make the measurement more accurate</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cpu</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ftimer</span> <span class="o">=</span> <span class="n">rt_mod</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="s2">&quot;run&quot;</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">repeat</span><span class="o">=</span><span class="n">n_repeat</span><span class="p">)</span>
<span class="n">prof_res</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ftimer</span><span class="p">()</span><span class="o">.</span><span class="n">results</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Elapsed average ms:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">prof_res</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Elapsed average ms: 17.0987343
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We recommend this method for the following reasons:</p>
<blockquote>
<div><ul class="simple">
<li><p>Measurements are done in C++, so there is no Python overhead</p></li>
<li><p>It includes several warm up runs</p></li>
<li><p>The same method can be used to profile on remote devices (android etc.).</p></li>
</ul>
</div></blockquote>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unless the hardware has special support for fast 8 bit instructions, quantized models are
not expected to be any faster than FP32 models. Without fast 8 bit instructions, TVM does
quantized convolution in 16 bit, even if the model itself is 8 bit.</p>
<p>For x86, the best performance can be achieved on CPUs with AVX512 instructions set.
In this case, TVM utilizes the fastest available 8 bit instructions for the given target.
This includes support for the VNNI 8 bit dot product instruction (CascadeLake or newer).</p>
<p>Moreover, the following general tips for CPU performance equally applies:</p>
<blockquote>
<div><ul class="simple">
<li><p>Set the environment variable TVM_NUM_THREADS to the number of physical cores</p></li>
<li><p>Choose the best target for your hardware, such as “llvm -mcpu=skylake-avx512” or
“llvm -mcpu=cascadelake” (more CPUs with AVX512 would come in the future)</p></li>
</ul>
</div></blockquote>
</div>
</div>
<div class="section" id="deploy-a-quantized-mxnet-model">
<h2>Deploy a quantized MXNet Model<a class="headerlink" href="#deploy-a-quantized-mxnet-model" title="Permalink to this headline">¶</a></h2>
<p>TODO</p>
</div>
<div class="section" id="deploy-a-quantized-tflite-model">
<h2>Deploy a quantized TFLite Model<a class="headerlink" href="#deploy-a-quantized-tflite-model" title="Permalink to this headline">¶</a></h2>
<p>TODO</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-frontend-deploy-prequantized-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8a7f17665207908e373e8146da09443a/deploy_prequantized.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_prequantized.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/78da213eae381b8ff94cc356ee7c5423/deploy_prequantized.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_prequantized.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

<div id="button" class="backtop"><img src="../../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  


    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>
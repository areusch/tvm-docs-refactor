.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_tutorials_relay_quick_start.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_tutorials_relay_quick_start.py:


.. _tutorial-relay-quick-start:

Quick Start Tutorial for Compiling Deep Learning Models
=======================================================
**Author**: `Yao Wang <https://github.com/kevinthesun>`_, `Truman Tian <https://github.com/SiNZeRo>`_

This example shows how to build a neural network with Relay python frontend and
generates a runtime library for Nvidia GPU with TVM.
Notice that you need to build TVM with cuda and llvm enabled.

Overview for Supported Hardware Backend of TVM
----------------------------------------------
The image below shows hardware backend currently supported by TVM:

.. image:: https://github.com/dmlc/web-data/raw/master/tvm/tutorial/tvm_support_list.png
     :align: center

In this tutorial, we'll choose cuda and llvm as target backends.
To begin with, let's import Relay and TVM.


.. code-block:: default


    import numpy as np

    from tvm import relay
    from tvm.relay import testing
    import tvm
    from tvm import te
    from tvm.contrib import graph_runtime








Define Neural Network in Relay
------------------------------
First, let's define a neural network with relay python frontend.
For simplicity, we'll use pre-defined resnet-18 network in Relay.
Parameters are initialized with Xavier initializer.
Relay also supports other model formats such as MXNet, CoreML, ONNX and
Tensorflow.

In this tutorial, we assume we will do inference on our device
and the batch size is set to be 1. Input images are RGB color
images of size 224 * 224. We can call the :any:`tvm.relay.TupleWrapper.astext()`
to show the network structure.


.. code-block:: default


    batch_size = 1
    num_class = 1000
    image_shape = (3, 224, 224)
    data_shape = (batch_size,) + image_shape
    out_shape = (batch_size, num_class)

    mod, params = relay.testing.resnet.get_workload(
        num_layers=18, batch_size=batch_size, image_shape=image_shape)

    # set show_meta_data=True if you want to show meta data
    print(mod.astext(show_meta_data=False))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    v0.0.4
    def @main(%data: Tensor[(1, 3, 224, 224), float32], %bn_data_gamma: Tensor[(3), float32], %bn_data_beta: Tensor[(3), float32], %bn_data_moving_mean: Tensor[(3), float32], %bn_data_moving_var: Tensor[(3), float32], %conv0_weight: Tensor[(64, 3, 7, 7), float32], %bn0_gamma: Tensor[(64), float32], %bn0_beta: Tensor[(64), float32], %bn0_moving_mean: Tensor[(64), float32], %bn0_moving_var: Tensor[(64), float32], %stage1_unit1_bn1_gamma: Tensor[(64), float32], %stage1_unit1_bn1_beta: Tensor[(64), float32], %stage1_unit1_bn1_moving_mean: Tensor[(64), float32], %stage1_unit1_bn1_moving_var: Tensor[(64), float32], %stage1_unit1_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_bn2_gamma: Tensor[(64), float32], %stage1_unit1_bn2_beta: Tensor[(64), float32], %stage1_unit1_bn2_moving_mean: Tensor[(64), float32], %stage1_unit1_bn2_moving_var: Tensor[(64), float32], %stage1_unit1_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit1_sc_weight: Tensor[(64, 64, 1, 1), float32], %stage1_unit2_bn1_gamma: Tensor[(64), float32], %stage1_unit2_bn1_beta: Tensor[(64), float32], %stage1_unit2_bn1_moving_mean: Tensor[(64), float32], %stage1_unit2_bn1_moving_var: Tensor[(64), float32], %stage1_unit2_conv1_weight: Tensor[(64, 64, 3, 3), float32], %stage1_unit2_bn2_gamma: Tensor[(64), float32], %stage1_unit2_bn2_beta: Tensor[(64), float32], %stage1_unit2_bn2_moving_mean: Tensor[(64), float32], %stage1_unit2_bn2_moving_var: Tensor[(64), float32], %stage1_unit2_conv2_weight: Tensor[(64, 64, 3, 3), float32], %stage2_unit1_bn1_gamma: Tensor[(64), float32], %stage2_unit1_bn1_beta: Tensor[(64), float32], %stage2_unit1_bn1_moving_mean: Tensor[(64), float32], %stage2_unit1_bn1_moving_var: Tensor[(64), float32], %stage2_unit1_conv1_weight: Tensor[(128, 64, 3, 3), float32], %stage2_unit1_bn2_gamma: Tensor[(128), float32], %stage2_unit1_bn2_beta: Tensor[(128), float32], %stage2_unit1_bn2_moving_mean: Tensor[(128), float32], %stage2_unit1_bn2_moving_var: Tensor[(128), float32], %stage2_unit1_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit1_sc_weight: Tensor[(128, 64, 1, 1), float32], %stage2_unit2_bn1_gamma: Tensor[(128), float32], %stage2_unit2_bn1_beta: Tensor[(128), float32], %stage2_unit2_bn1_moving_mean: Tensor[(128), float32], %stage2_unit2_bn1_moving_var: Tensor[(128), float32], %stage2_unit2_conv1_weight: Tensor[(128, 128, 3, 3), float32], %stage2_unit2_bn2_gamma: Tensor[(128), float32], %stage2_unit2_bn2_beta: Tensor[(128), float32], %stage2_unit2_bn2_moving_mean: Tensor[(128), float32], %stage2_unit2_bn2_moving_var: Tensor[(128), float32], %stage2_unit2_conv2_weight: Tensor[(128, 128, 3, 3), float32], %stage3_unit1_bn1_gamma: Tensor[(128), float32], %stage3_unit1_bn1_beta: Tensor[(128), float32], %stage3_unit1_bn1_moving_mean: Tensor[(128), float32], %stage3_unit1_bn1_moving_var: Tensor[(128), float32], %stage3_unit1_conv1_weight: Tensor[(256, 128, 3, 3), float32], %stage3_unit1_bn2_gamma: Tensor[(256), float32], %stage3_unit1_bn2_beta: Tensor[(256), float32], %stage3_unit1_bn2_moving_mean: Tensor[(256), float32], %stage3_unit1_bn2_moving_var: Tensor[(256), float32], %stage3_unit1_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit1_sc_weight: Tensor[(256, 128, 1, 1), float32], %stage3_unit2_bn1_gamma: Tensor[(256), float32], %stage3_unit2_bn1_beta: Tensor[(256), float32], %stage3_unit2_bn1_moving_mean: Tensor[(256), float32], %stage3_unit2_bn1_moving_var: Tensor[(256), float32], %stage3_unit2_conv1_weight: Tensor[(256, 256, 3, 3), float32], %stage3_unit2_bn2_gamma: Tensor[(256), float32], %stage3_unit2_bn2_beta: Tensor[(256), float32], %stage3_unit2_bn2_moving_mean: Tensor[(256), float32], %stage3_unit2_bn2_moving_var: Tensor[(256), float32], %stage3_unit2_conv2_weight: Tensor[(256, 256, 3, 3), float32], %stage4_unit1_bn1_gamma: Tensor[(256), float32], %stage4_unit1_bn1_beta: Tensor[(256), float32], %stage4_unit1_bn1_moving_mean: Tensor[(256), float32], %stage4_unit1_bn1_moving_var: Tensor[(256), float32], %stage4_unit1_conv1_weight: Tensor[(512, 256, 3, 3), float32], %stage4_unit1_bn2_gamma: Tensor[(512), float32], %stage4_unit1_bn2_beta: Tensor[(512), float32], %stage4_unit1_bn2_moving_mean: Tensor[(512), float32], %stage4_unit1_bn2_moving_var: Tensor[(512), float32], %stage4_unit1_conv2_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit1_sc_weight: Tensor[(512, 256, 1, 1), float32], %stage4_unit2_bn1_gamma: Tensor[(512), float32], %stage4_unit2_bn1_beta: Tensor[(512), float32], %stage4_unit2_bn1_moving_mean: Tensor[(512), float32], %stage4_unit2_bn1_moving_var: Tensor[(512), float32], %stage4_unit2_conv1_weight: Tensor[(512, 512, 3, 3), float32], %stage4_unit2_bn2_gamma: Tensor[(512), float32], %stage4_unit2_bn2_beta: Tensor[(512), float32], %stage4_unit2_bn2_moving_mean: Tensor[(512), float32], %stage4_unit2_bn2_moving_var: Tensor[(512), float32], %stage4_unit2_conv2_weight: Tensor[(512, 512, 3, 3), float32], %bn1_gamma: Tensor[(512), float32], %bn1_beta: Tensor[(512), float32], %bn1_moving_mean: Tensor[(512), float32], %bn1_moving_var: Tensor[(512), float32], %fc1_weight: Tensor[(1000, 512), float32], %fc1_bias: Tensor[(1000), float32]) -> Tensor[(1, 1000), float32] {
      %0 = nn.batch_norm(%data, %bn_data_gamma, %bn_data_beta, %bn_data_moving_mean, %bn_data_moving_var, epsilon=2e-05f, scale=False) /* ty=(Tensor[(1, 3, 224, 224), float32], Tensor[(3), float32], Tensor[(3), float32]) */;
      %1 = %0.0;
      %2 = nn.conv2d(%1, %conv0_weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;
      %3 = nn.batch_norm(%2, %bn0_gamma, %bn0_beta, %bn0_moving_mean, %bn0_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %4 = %3.0;
      %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */;
      %6 = nn.max_pool2d(%5, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %7 = nn.batch_norm(%6, %stage1_unit1_bn1_gamma, %stage1_unit1_bn1_beta, %stage1_unit1_bn1_moving_mean, %stage1_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %8 = %7.0;
      %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %10 = nn.conv2d(%9, %stage1_unit1_conv1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %11 = nn.batch_norm(%10, %stage1_unit1_bn2_gamma, %stage1_unit1_bn2_beta, %stage1_unit1_bn2_moving_mean, %stage1_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %12 = %11.0;
      %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %14 = nn.conv2d(%13, %stage1_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %15 = nn.conv2d(%9, %stage1_unit1_sc_weight, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %17 = nn.batch_norm(%16, %stage1_unit2_bn1_gamma, %stage1_unit2_bn1_beta, %stage1_unit2_bn1_moving_mean, %stage1_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %18 = %17.0;
      %19 = nn.relu(%18) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %20 = nn.conv2d(%19, %stage1_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %21 = nn.batch_norm(%20, %stage1_unit2_bn2_gamma, %stage1_unit2_bn2_beta, %stage1_unit2_bn2_moving_mean, %stage1_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %22 = %21.0;
      %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %24 = nn.conv2d(%23, %stage1_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %25 = add(%24, %16) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %26 = nn.batch_norm(%25, %stage2_unit1_bn1_gamma, %stage2_unit1_bn1_beta, %stage2_unit1_bn1_moving_mean, %stage2_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;
      %27 = %26.0;
      %28 = nn.relu(%27) /* ty=Tensor[(1, 64, 56, 56), float32] */;
      %29 = nn.conv2d(%28, %stage2_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %30 = nn.batch_norm(%29, %stage2_unit1_bn2_gamma, %stage2_unit1_bn2_beta, %stage2_unit1_bn2_moving_mean, %stage2_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
      %31 = %30.0;
      %32 = nn.relu(%31) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %33 = nn.conv2d(%32, %stage2_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %34 = nn.conv2d(%28, %stage2_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %35 = add(%33, %34) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %36 = nn.batch_norm(%35, %stage2_unit2_bn1_gamma, %stage2_unit2_bn1_beta, %stage2_unit2_bn1_moving_mean, %stage2_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
      %37 = %36.0;
      %38 = nn.relu(%37) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %39 = nn.conv2d(%38, %stage2_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %40 = nn.batch_norm(%39, %stage2_unit2_bn2_gamma, %stage2_unit2_bn2_beta, %stage2_unit2_bn2_moving_mean, %stage2_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
      %41 = %40.0;
      %42 = nn.relu(%41) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %43 = nn.conv2d(%42, %stage2_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %44 = add(%43, %35) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %45 = nn.batch_norm(%44, %stage3_unit1_bn1_gamma, %stage3_unit1_bn1_beta, %stage3_unit1_bn1_moving_mean, %stage3_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 128, 28, 28), float32], Tensor[(128), float32], Tensor[(128), float32]) */;
      %46 = %45.0;
      %47 = nn.relu(%46) /* ty=Tensor[(1, 128, 28, 28), float32] */;
      %48 = nn.conv2d(%47, %stage3_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %49 = nn.batch_norm(%48, %stage3_unit1_bn2_gamma, %stage3_unit1_bn2_beta, %stage3_unit1_bn2_moving_mean, %stage3_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
      %50 = %49.0;
      %51 = nn.relu(%50) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %52 = nn.conv2d(%51, %stage3_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %53 = nn.conv2d(%47, %stage3_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %54 = add(%52, %53) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %55 = nn.batch_norm(%54, %stage3_unit2_bn1_gamma, %stage3_unit2_bn1_beta, %stage3_unit2_bn1_moving_mean, %stage3_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
      %56 = %55.0;
      %57 = nn.relu(%56) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %58 = nn.conv2d(%57, %stage3_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %59 = nn.batch_norm(%58, %stage3_unit2_bn2_gamma, %stage3_unit2_bn2_beta, %stage3_unit2_bn2_moving_mean, %stage3_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
      %60 = %59.0;
      %61 = nn.relu(%60) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %62 = nn.conv2d(%61, %stage3_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %63 = add(%62, %54) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %64 = nn.batch_norm(%63, %stage4_unit1_bn1_gamma, %stage4_unit1_bn1_beta, %stage4_unit1_bn1_moving_mean, %stage4_unit1_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 256, 14, 14), float32], Tensor[(256), float32], Tensor[(256), float32]) */;
      %65 = %64.0;
      %66 = nn.relu(%65) /* ty=Tensor[(1, 256, 14, 14), float32] */;
      %67 = nn.conv2d(%66, %stage4_unit1_conv1_weight, strides=[2, 2], padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %68 = nn.batch_norm(%67, %stage4_unit1_bn2_gamma, %stage4_unit1_bn2_beta, %stage4_unit1_bn2_moving_mean, %stage4_unit1_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
      %69 = %68.0;
      %70 = nn.relu(%69) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %71 = nn.conv2d(%70, %stage4_unit1_conv2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %72 = nn.conv2d(%66, %stage4_unit1_sc_weight, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %73 = add(%71, %72) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %74 = nn.batch_norm(%73, %stage4_unit2_bn1_gamma, %stage4_unit2_bn1_beta, %stage4_unit2_bn1_moving_mean, %stage4_unit2_bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
      %75 = %74.0;
      %76 = nn.relu(%75) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %77 = nn.conv2d(%76, %stage4_unit2_conv1_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %78 = nn.batch_norm(%77, %stage4_unit2_bn2_gamma, %stage4_unit2_bn2_beta, %stage4_unit2_bn2_moving_mean, %stage4_unit2_bn2_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
      %79 = %78.0;
      %80 = nn.relu(%79) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %81 = nn.conv2d(%80, %stage4_unit2_conv2_weight, padding=[1, 1, 1, 1], channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %82 = add(%81, %73) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %83 = nn.batch_norm(%82, %bn1_gamma, %bn1_beta, %bn1_moving_mean, %bn1_moving_var, epsilon=2e-05f) /* ty=(Tensor[(1, 512, 7, 7), float32], Tensor[(512), float32], Tensor[(512), float32]) */;
      %84 = %83.0;
      %85 = nn.relu(%84) /* ty=Tensor[(1, 512, 7, 7), float32] */;
      %86 = nn.global_avg_pool2d(%85) /* ty=Tensor[(1, 512, 1, 1), float32] */;
      %87 = nn.batch_flatten(%86) /* ty=Tensor[(1, 512), float32] */;
      %88 = nn.dense(%87, %fc1_weight, units=1000) /* ty=Tensor[(1, 1000), float32] */;
      %89 = nn.bias_add(%88, %fc1_bias, axis=-1) /* ty=Tensor[(1, 1000), float32] */;
      nn.softmax(%89) /* ty=Tensor[(1, 1000), float32] */
    }





Compilation
-----------
Next step is to compile the model using the Relay/TVM pipeline.
Users can specify the optimization level of the compilation.
Currently this value can be 0 to 3. The optimization passes include
operator fusion, pre-computation, layout transformation and so on.

:py:func:`relay.build` returns three components: the execution graph in
json format, the TVM module library of compiled functions specifically
for this graph on the target hardware, and the parameter blobs of
the model. During the compilation, Relay does the graph-level
optimization while TVM does the tensor-level optimization, resulting
in an optimized runtime module for model serving.

We'll first compile for Nvidia GPU. Behind the scene, :py:func:`relay.build`
first does a number of graph-level optimizations, e.g. pruning, fusing, etc.,
then registers the operators (i.e. the nodes of the optimized graphs) to
TVM implementations to generate a `tvm.module`.
To generate the module library, TVM will first transfer the high level IR
into the lower intrinsic IR of the specified target backend, which is CUDA
in this example. Then the machine code will be generated as the module library.


.. code-block:: default


    opt_level = 3
    target = tvm.target.cuda()
    with relay.build_config(opt_level=opt_level):
        graph, lib, params = relay.build(mod, target, params=params)



.. rst-class:: sphx-glr-script-out


.. code-block:: pytb

    Traceback (most recent call last):
      File "/Users/andrew/.local/share/virtualenvs/tvm2-a-rOq6b-/lib/python3.7/site-packages/sphinx_gallery/gen_gallery.py", line 159, in call_memory
        return 0., func()
      File "/Users/andrew/.local/share/virtualenvs/tvm2-a-rOq6b-/lib/python3.7/site-packages/sphinx_gallery/gen_rst.py", line 466, in __call__
        exec(self.code, self.fake_main.__dict__)
      File "/Users/andrew/ws/tvm2/tutorials/relay_quick_start.py", line 100, in <module>
        graph, lib, params = relay.build(mod, target, params=params)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/build_module.py", line 251, in build
        graph_json, mod, params = bld_mod.build(mod, target, target_host, params)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/build_module.py", line 120, in build
        self._build(mod, target, target_host)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 225, in __call__
        raise get_last_ffi_error()
    tvm._ffi.base.TVMError: Traceback (most recent call last):
      [bt] (8) 9   libtvm.dylib                        0x0000000112f35c3f tvm::NodeFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*)>::operator()(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*) const + 255
      [bt] (7) 8   libtvm.dylib                        0x0000000112f37288 tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>::InitVTable()::'lambda4'(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*)::__invoke(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*) + 24
      [bt] (6) 7   libtvm.dylib                        0x0000000112f33fd0 tvm::relay::ScheduleGetter::VisitExpr_(tvm::relay::CallNode const*) + 400
      [bt] (5) 6   libtvm.dylib                        0x0000000112f33390 tvm::relay::backend::MemoizedExprTranslator<tvm::runtime::Array<tvm::te::Tensor, void> >::VisitExpr(tvm::RelayExpr const&) + 352
      [bt] (4) 5   libtvm.dylib                        0x0000000112f3596a tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>::VisitExpr(tvm::RelayExpr const&) + 138
      [bt] (3) 4   libtvm.dylib                        0x0000000112f35c3f tvm::NodeFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*)>::operator()(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*) const + 255
      [bt] (2) 3   libtvm.dylib                        0x0000000112f37288 tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>::InitVTable()::'lambda4'(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*)::__invoke(tvm::runtime::ObjectRef const&, tvm::relay::ExprFunctor<tvm::runtime::Array<tvm::te::Tensor, void> (tvm::RelayExpr const&)>*) + 24
      [bt] (1) 2   libtvm.dylib                        0x0000000112f344da tvm::relay::ScheduleGetter::VisitExpr_(tvm::relay::CallNode const*) + 1690
      [bt] (0) 1   libtvm.dylib                        0x000000011308d115 std::__1::__function::__func<TVMFuncCreateFromCFunc::$_2, std::__1::allocator<TVMFuncCreateFromCFunc::$_2>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 213
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 78, in cfun
        rv = local_pyfunc(*pyargs)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/backend/compile_engine.py", line 250, in lower_call
        op, call.attrs, inputs, ret_type, target)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/backend/compile_engine.py", line 183, in select_implementation
        all_impls = get_valid_implementations(op, attrs, inputs, out_type, target)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/backend/compile_engine.py", line 124, in get_valid_implementations
        strategy = fstrategy(attrs, inputs, out_type, target)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/target/generic_func.py", line 45, in __call__
        return _ffi_api.GenericFuncCallFunc(self, *args)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 225, in __call__
        raise get_last_ffi_error()
      [bt] (5) 6   ???                                 0x00007ffeeb4540d0 0x0 + 140732845605072
      [bt] (4) 5   _ctypes.cpython-37m-darwin.so       0x0000000105517347 ffi_call_unix64 + 79
      [bt] (3) 4   libtvm.dylib                        0x000000011308a7e8 TVMFuncCall + 72
      [bt] (2) 3   libtvm.dylib                        0x0000000112aa69e2 std::__1::__function::__func<tvm::$_5, std::__1::allocator<tvm::$_5>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 178
      [bt] (1) 2   libtvm.dylib                        0x0000000112aa495f tvm::GenericFunc::CallPacked(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const + 703
      [bt] (0) 1   libtvm.dylib                        0x000000011308d115 std::__1::__function::__func<TVMFuncCreateFromCFunc::$_2, std::__1::allocator<TVMFuncCreateFromCFunc::$_2>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 213
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 78, in cfun
        rv = local_pyfunc(*pyargs)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/relay/op/strategy/cuda.py", line 444, in dense_strategy_cuda
        if nvcc.have_tensorcore(tvm.gpu(0).compute_version):
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/runtime_ctypes.py", line 223, in compute_version
        self.device_type, self.device_id, 4)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/runtime_ctypes.py", line 185, in _GetDeviceAttr
        device_type, device_id, attr_id)
      File "/Users/andrew/ws/tvm2/docs/../python/tvm/_ffi/_ctypes/packed_func.py", line 225, in __call__
        raise get_last_ffi_error()
      [bt] (6) 7   ???                                 0x00007ffeeb452ae0 0x0 + 140732845599456
      [bt] (5) 6   _ctypes.cpython-37m-darwin.so       0x0000000105517347 ffi_call_unix64 + 79
      [bt] (4) 5   libtvm.dylib                        0x000000011308a7e8 TVMFuncCall + 72
      [bt] (3) 4   libtvm.dylib                        0x000000011308d569 std::__1::__function::__func<$_4, std::__1::allocator<$_4>, void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)>::operator()(tvm::runtime::TVMArgs&&, tvm::runtime::TVMRetValue*&&) + 217
      [bt] (2) 3   libtvm.dylib                        0x000000011308bbd3 tvm::runtime::DeviceAPIManager::GetAPI(int, bool) + 371
      [bt] (1) 2   libtvm.dylib                        0x000000011308bdf3 tvm::runtime::DeviceAPIManager::GetAPI(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, bool) + 371
      [bt] (0) 1   libtvm.dylib                        0x000000011268220f dmlc::LogMessageFatal::~LogMessageFatal() + 111
      File "../src/runtime/c_runtime_api.cc", line 131
    TVMError: Check failed: allow_missing: Device API gpu is not enabled.




Run the generate library
------------------------
Now we can create graph runtime and run the module on Nvidia GPU.


.. code-block:: default


    # create random input
    ctx = tvm.gpu()
    data = np.random.uniform(-1, 1, size=data_shape).astype("float32")
    # create module
    module = graph_runtime.create(graph, lib, ctx)
    # set input and parameters
    module.set_input("data", data)
    module.set_input(**params)
    # run
    module.run()
    # get output
    out = module.get_output(0, tvm.nd.empty(out_shape)).asnumpy()

    # Print first 10 elements of output
    print(out.flatten()[0:10])


Save and Load Compiled Module
-----------------------------
We can also save the graph, lib and parameters into files and load them
back in deploy environment.


.. code-block:: default


    # save the graph, lib and params into separate files
    from tvm.contrib import util

    temp = util.tempdir()
    path_lib = temp.relpath("deploy_lib.tar")
    lib.export_library(path_lib)
    with open(temp.relpath("deploy_graph.json"), "w") as fo:
        fo.write(graph)
    with open(temp.relpath("deploy_param.params"), "wb") as fo:
        fo.write(relay.save_param_dict(params))
    print(temp.listdir())



.. code-block:: default


    # load the module back.
    loaded_json = open(temp.relpath("deploy_graph.json")).read()
    loaded_lib = tvm.runtime.load_module(path_lib)
    loaded_params = bytearray(open(temp.relpath("deploy_param.params"), "rb").read())
    input_data = tvm.nd.array(np.random.uniform(size=data_shape).astype("float32"))

    module = graph_runtime.create(loaded_json, loaded_lib, ctx)
    module.load_params(loaded_params)
    module.run(data=input_data)
    out_deploy = module.get_output(0).asnumpy()

    # Print first 10 elements of output
    print(out_deploy.flatten()[0:10])

    # check whether the output from deployed module is consistent with original one
    tvm.testing.assert_allclose(out_deploy, out, atol=1e-3)


.. _sphx_glr_download_tutorials_relay_quick_start.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: relay_quick_start.py <relay_quick_start.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: relay_quick_start.ipynb <relay_quick_start.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
